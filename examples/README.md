# Example Data and Pipeline Walkthrough

This directory contains a tiny synthetic FHIR Patient export and the expected
OMOP PERSON table produced by the ETL.

## Sample Files

* `sample_patient.ndjson` – one Patient resource generated by [Synthea](https://synthetichealth.github.io/synthea/).
  It is the starting point for the pipeline and demonstrates the structure of
  Synthea's FHIR NDJSON output.
* `sample_omop_person.csv` – the OMOP PERSON row produced by running the mapping
  logic on the above patient.  Use it as a reference for the expected column
  layout.

## Walkthrough

```python
from pyspark.sql import SparkSession
from fhiromop.parser import read_patient_ndjson
from fhiromop.config import load_mapping
from fhiromop.mapper import map_person
from fhiromop.loader import save_person
from fhiromop.qc import run_checks

spark = SparkSession.builder.getOrCreate()

# 1. Parse the NDJSON file into a flattened DataFrame
patients = read_patient_ndjson(spark, "examples/sample_patient.ndjson")

# 2. Map the patient fields into OMOP PERSON columns
config = load_mapping("mapping/fhir_to_omop_person.yaml")
person = map_person(patients, config)

# 3. Save the PERSON table as CSV
save_person(person, "examples/sample_omop_person.csv")

# 4. Run basic quality checks
summary = run_checks(person, "examples/sample_omop_person.csv")
print(summary)
```

The script parses the sample NDJSON, converts it into the OMOP PERSON schema,
writes a CSV file, and verifies row counts and null values.
